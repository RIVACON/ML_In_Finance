{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../images/logo.png\" alt=\"Your Image\" style=\"width: 500px; height: auto\"></center>\n",
    "\n",
    "# Approx. valuation of an at-the-money call option via a Kolmogorov-Arnold Network\n",
    "\n",
    "\n",
    "In this notebook, we show based on the example of an approximate formula for pricing an at-the-money call option how a Kolmogorov-Arnold Network (KAN) can be used for the approximation and fast evaluation of classical valuation methods.\n",
    "\n",
    "For basics about the pricing of a call option with the Black-Scholes-Merton model, see here: [European Call Option](Time_Series_Predicition/Predicting_Stock_Prices_ESN.ipynb). For the at-the-money call option, we have $S = K e^{-r(T-t)}$, such that plugging this into the standard Black-Scholes formula gets us:\n",
    "\n",
    "$C(S,t) = N(0.5 \\sigma \\sqrt{T-t}) -  N(-0.5 \\sigma \\sqrt{T-t})$. \n",
    "\n",
    "Taylor approximation implies for small $x$, that\n",
    "\n",
    "$N(x) = N(0) + N'(0) x + \\mathcal{O}(x^2) $,\n",
    "\n",
    "such that with $N'(0) = 1/\\sqrt{2 \\pi}$ (and $r = 0$) the appoximation of the price $C$ of a at-the-money call with maturity $T$ and volatility $\\sigma$ is given by the equation:\n",
    "\n",
    "$C(S,t) \\approx 0.4 S \\sigma \\sqrt{T-t} $.\n",
    "\n",
    "\n",
    "\n",
    "What makes KANs special is, that they have learnable activation functions on edges (“weights”) and no linear weights at all, meaning every\n",
    "weight parameter is replaced by a univariate function parametrized as a spline. For more details about the relevant principles of Kolmogorov-Arnold Networks, please refer to https://arxiv.org/pdf/2404.19756. Note, that the implementation and application to our use case here is based on https://github.com/KindXiaoming/pykan?tab=readme-ov-file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import math\n",
    "from numbers import Number\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "from kan import *\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and plot data\n",
    "\n",
    "Given data points (T,sigma,S,call_price), we are interested in figuring out the symbolic formula. \n",
    "\n",
    "We create input data for the training of the neural network, including\n",
    "- time to maturity (T)\n",
    "- volatility (sigma)\n",
    "- spot (S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_ATM_euro_vanilla_call(S_times_sigma, T):\n",
    "    \"\"\" \n",
    "    Compute an approximation of an at-the-money European call price\n",
    "    \"\"\"\n",
    "    call = 0.4*S_times_sigma*torch.sqrt(T)\n",
    "    return call\n",
    "\n",
    "\n",
    "def create_dataset(f, \n",
    "                   n_var=2, \n",
    "                   f_mode = 'col',\n",
    "                   train_num=1000, \n",
    "                   test_num=1000,\n",
    "                   normalize_input=False,\n",
    "                   normalize_label=False,\n",
    "                   device='cpu',\n",
    "                   seed=42):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    train_input = torch.zeros(train_num, n_var)\n",
    "    test_input = torch.zeros(test_num, n_var)\n",
    "    \n",
    "    # time to maturity\n",
    "    train_input[:,0] = torch.rand(train_num,)*(1.-0.1)+0.1\n",
    "    test_input[:,0] = torch.rand(test_num,)*(1.-0.1)+0.1\n",
    "    # vol*spot\n",
    "    train_input[:,1] = (torch.rand(train_num,)*(0.3-0.05)+0.05)*(torch.rand(train_num,)*(1.1-0.9)+0.9)\n",
    "    test_input[:,1] = (torch.rand(train_num,)*(0.3-0.05)+0.05)*(torch.rand(train_num,)*(1.1-0.9)+0.9)\n",
    "\n",
    "    if f_mode == 'col':\n",
    "        train_label = f(train_input)\n",
    "        test_label = f(test_input)\n",
    "    elif f_mode == 'row':\n",
    "        train_label = f(train_input.T)\n",
    "        test_label = f(test_input.T)\n",
    "    else:\n",
    "        print(f'f_mode {f_mode} not recognized')\n",
    "        \n",
    "    # if has only 1 dimension\n",
    "    if len(train_label.shape) == 1:\n",
    "        train_label = train_label.unsqueeze(dim=1)\n",
    "        test_label = test_label.unsqueeze(dim=1)\n",
    "        \n",
    "    def normalize(data, mean, std):\n",
    "            return (data-mean)/std\n",
    "            \n",
    "    if normalize_input == True:\n",
    "        mean_input = torch.mean(train_input, dim=0, keepdim=True)\n",
    "        std_input = torch.std(train_input, dim=0, keepdim=True)\n",
    "        train_input = normalize(train_input, mean_input, std_input)\n",
    "        test_input = normalize(test_input, mean_input, std_input)\n",
    "        \n",
    "    if normalize_label == True:\n",
    "        mean_label = torch.mean(train_label, dim=0, keepdim=True)\n",
    "        std_label = torch.std(train_label, dim=0, keepdim=True)\n",
    "        train_label = normalize(train_label, mean_label, std_label)\n",
    "        test_label = normalize(test_label, mean_label, std_label)\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['train_input'] = train_input.to(device)\n",
    "    dataset['test_input'] = test_input.to(device)\n",
    "\n",
    "    dataset['train_label'] = train_label.to(device)\n",
    "    dataset['test_label'] = test_label.to(device)\n",
    "\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: approx_ATM_euro_vanilla_call(x[:,[1]],x[:,[0]])\n",
    "dataset = create_dataset(f)\n",
    "dataset['train_input'].shape, dataset['train_label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(dataset['train_input'][:,1], bins=20, alpha=0.5, label='training')\n",
    "plt.hist(dataset['test_input'][:,1], bins=20, alpha=0.5, label='test')\n",
    "plt.xlabel('S*vol')\n",
    "plt.ylabel('#points')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(dataset['train_input'][:,0], bins=20, alpha=0.5, label='training')\n",
    "plt.hist(dataset['test_input'][:,0], bins=20, alpha=0.5, label='test')\n",
    "plt.xlabel('time to maturity')\n",
    "plt.ylabel('#points');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training the KAN\n",
    "\n",
    "In this section, we build and train the KAN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with sparsification.\n",
    "\n",
    " Starting from a fully-connected [2,5,1] KAN (i.e., the function includes 2D inputs, 1D output, and 5 hidden neurons).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "model = KAN(width=[2,5,1], grid=10, k=3, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initialization of the model can be vizualized by calling the plot method on the model.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(dataset['train_input']);\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "In this section, we train the KAN.\n",
    "Note: small bug fix for pykan 0.2.3: https://github.com/KindXiaoming/pykan/issues/375\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, opt=\"LBFGS\", steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.prune()\n",
    "model(dataset['train_input'])\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, opt=\"LBFGS\", steps=50);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, opt=\"LBFGS\", steps=200);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.auto_symbolic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, opt=\"LBFGS\", steps=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the symbolic formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = model.symbolic_formula()[0][0]\n",
    "ex_round(formula,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rivapyFS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
